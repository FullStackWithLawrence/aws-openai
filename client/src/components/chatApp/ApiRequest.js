/*-----------------------------------------------------------------------------
 Description: This file contains the function that makes the API request to
 the backend. It is called exclusively from chatApp/Component.jsx

 Notes:
  - The backend API is an AWS API Gateway endpoint that is configured to
    call an AWS Lambda function. The Lambda function is written in Python
    and calls the OpenAI API.

  - The backend API is configured to require an API key. The API key is
    passed in the header of the request. In real terms, the api key is
    pointless because it is exposed in the client code. However, it is
    required by the API Gateway configuration.

  - The backend API is configured to allow CORS requests from the client.
    This is necessary because the client and backend are served from
    different domains.

 Returns: the backend API is configured to return a JSON object that substantially
    conforms to the following structure for all 200 responses:
           {
             "isBase64Encoded": false,
             "statusCode": 200,
             "body": {
                 "id": "chatcmpl-8B4RwgebWS8ZdTQ1ppHgElsru0BVW",
                 "object": "chat.completion",
                 "created": 1697649404,
                 "model": "gpt-3.5-turbo-0613",
                 "choices": [
                     {
                         "index": 0,
                         "message": {
                             "role": "assistant",
                             "content": "Quantum computing is a type of computing that uses tiny particles called quantum bits, or qubits, to process and store information. It's like regular computers, but instead of using regular bits that can be either 0 or 1, quantum computers use qubits that can be both 0 and 1 at the same time. This allows them to solve certain problems much faster than regular computers. Quantum computers are very advanced and not widely used yet, but scientists are working on developing them to help solve complex problems in areas like science, medicine, and cryptography."
                         },
                         "finish_reason": "stop"
                     }
                 ],
                 "usage": {
                     "prompt_tokens": 30,
                     "completion_tokens": 113,
                     "total_tokens": 143
                 }
             }
           }
-----------------------------------------------------------------------------*/

export async function processApiRequest(chatMessage, apiURL, apiKey, openChatModal) {
  const init = {
    method: 'POST',
    mode: 'cors',
    headers: {
      'x-api-key': apiKey,
      'Accept': '*/*',
      'Content-Type': 'application/json',
      'Origin': window.location.origin
    },
    body: JSON.stringify({
      'input_text': chatMessage
    }),
  };
  try {
    const response = await fetch(apiURL, init);
    const status = await response.status;
    const response_json = await response.json();    // Convert the ReadableStream to a JSON object
    const response_body = await response_json.body; // ditto

    if (response.ok) {
      return response_body;
    }
    else {
      /*
        note:
        - the response_body object is not available when the status is 504, because
          these responses are generated exclusively by API Gateway.
        - the response_body object is potentially not available when the status is 500
          depending on whether the 500 response was generated by the Lambda or the API Gateway
        - the response_body object is intended to always be available when the status is 400.
          However, there potentially COULD be a case where the response itself contains message text.
      */
      let errTitle = 'Error ' + status;
      let errMessage = 'An unknown error occurred.';
      switch (status) {
        case 400:
          errMessage = response.statusText || response_body.message || 'The request was invalid.';
          break;
        case 500:
          errMessage = response.statusText || response_body.message || 'An internal server error occurred.';
          break;
        case 504:
          errMessage = response.statusText || 'Gateway timeout error. This is a known consequence of using AWS Lambda for integrations to the OpenAI API. Note that AWS Lambda has a hard 29 second timeout. If OpenAI requests take longer, which is frequently the case with chatgpt-4 then you will receive this error. If the timeout persists then you might try using chatgpt-3.5 instead as it is more performant.';
          break;
      }
      openChatModal(errTitle, errMessage);
    }
  } catch (error) {
    openChatModal('Error', error);
    return;
  }
}
