{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e397c236",
   "metadata": {},
   "source": [
    "# OpenAI API Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab24c72d",
   "metadata": {},
   "source": [
    "OpenAI publishes a Python API library that you can use to interact with their Large Language Models like ChatGPT, GPT-4, and Dall-E.\n",
    "\n",
    "\n",
    "OpenAI account: https://platform.openai.com\n",
    "API Keys: https://platform.openai.com/api-keys\n",
    "\n",
    "You'll need an account, and you'll also need to generate an API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c14fb",
   "metadata": {},
   "source": [
    "## Import the OpenAI API library source code into the Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the openai Python library\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5865d24",
   "metadata": {},
   "source": [
    "## Initialize the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENTS\n",
    "OPENAI_API_KEY = \"YOUR OPENAI API KEY GOES HERE\"\n",
    "OPENAI_API_ORGANIZATION = \"YOUR OPENAI ORG ID GOES HERE\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# INSTRUCTOR ONLY\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "  from dotenv import find_dotenv, load_dotenv\n",
    "except ImportError:\n",
    "    %pip install python-dotenv\n",
    "    from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "dotenv_path = find_dotenv()\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, verbose=True)\n",
    "    OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "    OPENAI_API_ORGANIZATION = os.environ[\"OPENAI_API_ORGANIZATION\"]\n",
    "else:\n",
    "    raise FileNotFoundError(\"No .env file found in root directory of repository\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0e35e",
   "metadata": {},
   "source": [
    "## Create an instance of the OpenAI class\n",
    "\n",
    "We also need to pass our API key into this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e443aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will allow us to make requests to the OpenAI API\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d1234",
   "metadata": {},
   "source": [
    "## Create a helper function to manage API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_response(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4-turbo',\n",
    "        max_tokens=256,\n",
    "        temperature=0.50,\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1747d94",
   "metadata": {},
   "source": [
    "## Configure the system role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd977e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_ROLE = \"\"\"You are a helpful assistant\"\"\"\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": SYSTEM_ROLE\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc33c8",
   "metadata": {},
   "source": [
    "## Prompt your chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db506e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Where do cranberries grow best?\"\"\"\n",
    "\n",
    "# 1.) Append our prompt to the messages list\n",
    "messages.append({\n",
    "    \"role\": \"user\", \n",
    "    \"content\": prompt\n",
    "})\n",
    "\n",
    "# 2.) Invoke the OpenAI API\n",
    "response = llm_response(messages)\n",
    "\n",
    "# 3.) Append the OpenAI API response to the messages list.\n",
    "messages.append({\n",
    "    \"role\": \"assistant\", \n",
    "    \"content\": response\n",
    "})\n",
    "\n",
    "# 4.) Print the formatted messages list to the console.\n",
    "print(json.dumps(messages, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab6e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
